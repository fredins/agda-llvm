% !TEX program = lualatex
\documentclass[10pt, twocolumn]{article}
% \usepackage{a4wide}

%\usepackage[a4paper, total={8.5in, 11in}]{geometry}
% \usepackage[a4paper]{geometry}
\usepackage[a4paper, margin=2.5cm]{geometry}
%\setlength{\textheight}{1.1\textheight}

% Support for Agda code.
\usepackage{agda}

\usepackage{fontspec}
\newfontfamily{\AgdaSerifFont}{Latin Modern Roman}
\newfontfamily{\AgdaSansSerifFont}{Latin Modern Sans}
\newfontfamily{\AgdaTypewriterFont}{Latin Modern Mono}
\renewcommand{\AgdaFontStyle}[1]{{\AgdaSansSerifFont{}#1}}
\renewcommand{\AgdaKeywordFontStyle}[1]{{\AgdaSansSerifFont{}#1}}
\renewcommand{\AgdaStringFontStyle}[1]{{\AgdaTypewriterFont{}#1}}
\renewcommand{\AgdaCommentFontStyle}[1]{{\AgdaTypewriterFont{}#1}}
\renewcommand{\AgdaBoundFontStyle}[1]{\textit{\AgdaSerifFont{}#1}}

% Bibliography
\usepackage[backend=biber, style=apa, natbib=true]{biblatex}
\addbibresource{../bibliography.bib}

% Packages
\usepackage{empheq} % for border around math
\usepackage{listings} % non-agda code blocks
\usepackage{amssymb} % math symbols
\usepackage[]{lmodern} % Latin modern font
\usepackage[labelfont=bf, textfont=it, justification=centering, singlelinecheck=false]{caption} 
\usepackage{caption}
\usepackage{subcaption}
\usepackage[skip=8pt plus1pt, indent=10pt]{parskip}

\usepackage[framemethod=tikz]{mdframed}
\mdfsetup{%
innertopmargin=1em,
innerbottommargin=1em,
innerleftmargin=1em,
innerrightmargin=1em,
linewidth=0.5pt,
}

\usepackage{color}
\newcommand{\hl}[2][lightgray]{\colorbox{#1}{#2}}

% Cosmetics
\linespread{1.25}

\usepackage{newunicodechar}
\usepackage{colonequals}
\newunicodechar{λ}{\ensuremath{\mathnormal{\lambda}}}
\newunicodechar{∀}{\ensuremath{\mathnormal{\forall}}}
\newunicodechar{∷}{\ensuremath{\mathnormal{\coloncolon}}}
\newunicodechar{ω}{\ensuremath{\mathnormal{\omega}}}
\newunicodechar{ℕ}{\ensuremath{\mathbb{N}}}

\newunicodechar{₁}{\ensuremath{{}_1}}
\newunicodechar{₂}{\ensuremath{{}_2}}
\newunicodechar{₃}{\ensuremath{{}_3}}
\newunicodechar{₄}{\ensuremath{{}_4}}
\newunicodechar{₅}{\ensuremath{{}_5}}
\newunicodechar{₆}{\ensuremath{{}_6}}
\newunicodechar{₇}{\ensuremath{{}_7}}
\newunicodechar{₈}{\ensuremath{{}_8}}
\newunicodechar{₉}{\ensuremath{{}_9}}


\usepackage{listings}
\lstdefinelanguage{treeless}{
keywords={case, of, let, in}
}
\lstdefinelanguage{grin}{
keywords={case, of, store, update, unit, fetch}
}

\lstset{
frame=none,
framexleftmargin=4pt,
framesep=10pt,
stepnumber=1,
numbers=none,
numbersep=5pt,
numberstyle=\ttfamily\tiny\color[gray]{0.3},
basicstyle=\linespread{1}\ttfamily\fontseries{l}\selectfont,
keywordstyle=\linespread{1}\ttfamily\fontseries{b}\selectfont,
captionpos=b,
language=grin,
commentstyle=\it,
columns=flexible,
keepspaces=true,
mathescape=true,
escapechar=!,
}

\title{ Precise reference counting for lazy functional languages with interprocedural analysis}
\author{Martin Fredin \\ \texttt{fredinm@chalmers.se}}
\date{2023}

\begin{document}

\maketitle


\begin{code}[hide]
open import Agda.Builtin.Nat using (suc; zero; _+_) renaming (Nat to ℕ) 

infixr 5 _∷_
data List A : Set where
  []  : List A
  _∷_ : (x : A) (xs : List A) → List A
\end{code}

\begin{abstract}
Precise reference counting is a technique by \citeauthor{reinking2021} that uses ownership to deallocate objects as soon as possible. 
The algorithm is called Perceus, and as of this writing, it has only been implemented for eager functional languages.
This paper describes the implementation of a new lazy compiler back-end for the Agda programming language with 
precise reference counting. 
The compiler uses \citeauthor{boquist1999} and \citeauthor{johnsson1991}'s intermediate language GRIN to compile lazy programs. 
GRIN uses interprocedural analysis to inline the evaluation of suspended computations.
We extend GRIN with a variant of Perceus, and demonstrate the applicability of combining lazy functional programming with precise reference counting by developing a GRIN interpreter and an LLVM code generator. 

\end{abstract}

\section{Introduction}

Reference counting \citep{collins1960} is a memory management technique which can detect and free resources as soon as they are no longer needed, allowing memory reuse and destructive updates. 
Common reference counting algorithms are easy to implement; each allocation contains an extra field which tracks the number of references to an object. 
When the reference count reaches zero, the heap space occupied by the object is reclaimed.
The number of references to a object is updated by interleaved reference counting operations (\texttt{dup} and \texttt{drop}), which increments and decrements the reference count at runtime. 
As a result of the interleaved collection strategy, memory usage remain low and the throughput is continuous throughout the computation\footnote{Reference counted programs may introduce pauses similar to tracing garbage collectors. For example, when decrementing a long linked list all at once.} \citep{jones1996}.
Still, tracing garbage collectors are usually favored over reference counting implementations due to cheaper allocations, higher throughput, and the ability to collect cyclic data structures.

\citet{reinking2021} reexamine reference counting with a new approach, utilizing static guarantees to make the algorithm precise so objects can be deallocated as soon as possible.
They present a formalized algorithm called Perceus, which ensures preciseness. 
Perceus is implemented in the functional language Koka, along with optimizations for reducing reference counting operations and reusing memory.
This, builds upon previous work by \citet{ullrich2021} in the Lean programming language and theorem prover. 

Both Koka and Lean are, however, eagerly evaluated. 
Lazy languages pose an extra challenge for compiler writers because of their unintuitive control flow. 
In this paper, we adapt the Perceus algorithm to a new lazy compiler back-end for the Agda programming language and proof assistant.
As a first step, we transform Agda into an intermediate language called GRIN \citep{johnsson1991}.

\section{Graph Reduction Intermediate Notation}
In \citeyear{johnsson1991}, \citeauthor{johnsson1991} presented the Graph Reduction Intermediate Notation (GRIN) as an imperative version of the G-machine \citep{johnsson1984}, where lexically scoped variables are stored in registers instead of the stack. 
Later, GRIN was reformulated with a more "functional flavor" \citep{boquist1995}.
In this project, we introduce an additional variant of GRIN adapted for the internal representation of Agda and precise reference counting. 

The syntax of our variant are shown in Figure \ref{fig:grin-syntax}.
There are 4 kinds of constructs; terms, values, lambda patterns, and case patterns.
All syntactically correct expressions are not valid. For example, the value at the function position of an application must be either a top-level function (\emph{def}) or a primitive (\emph{prim}). It cannot be a variable because
there are no indirect function calls in GRIN. Likewise, top-level functions cannot be passed 
as arguments because GRIN is a first-order language.


\begingroup
\setlength{\fboxsep}{1em} % padding for border
\begin{figure*}[htbp]
\centering
\begin{empheq}[box=\fbox]{align*}
&\begin{array}{l l l l}
term & ::=      & term \; ; \; \lambda lpat \rightarrow term                & \; \text{binding} \\
     & \; \mid  & \texttt{case} \; val \; \texttt{of} \; term \; \{calt\}*  & \; \text{case} \\
     & \; \mid  & val \; \{val\}*                                           & \; \text{application} \\
     & \; \mid  & \texttt{unit} \; val                                      & \; \text{return value} \\
     & \; \mid  & \texttt{store} \; val                                     & \; \text{allocate new heap node} \\
        & \; \mid  & \texttt{fetch} \; \{tag\} \; n \;  \{i\}                  & \; \text{load heap node} \\
        & \; \mid  & \texttt{update} \; \{tag\} \; n \; \{i\} \; val           & \; \text{overwrite heap node} \\
        & \; \mid  & \texttt{unreachable}                                      & \; \text{unreachable} \\
\end{array} \\ \\
&\begin{array}{l l l l}
val & ::=     & tag \; \{val\}* & \; \text{constant node} \\
    & \; \mid & n \; \{val\}*   & \; \text{variable node} \\
    & \; \mid & tag             & \; \text{single tag} \\
    & \; \mid & ()              & \; \text{empty} \\
    & \; \mid & lit             & \; \text{literal} \\
    & \; \mid & n               & \; \text{variable (de Bruijn index)} \\
    & \; \mid & def             & \; \text{function definition} \\
    & \; \mid & prim            & \; \text{primitive definition} \\
\end{array} \\ \\
&\begin{array}{l l l l}
lpat & ::=     & tag \; \{x\}* & \; \text{constant node pattern} \\
     & \; \mid & x \; \{x\}*   & \; \text{variable node pattern} \\
     & \; \mid & ()            & \; \text{empty pattern} \\
     & \; \mid & x             & \; \text{variable pattern} \\
\end{array} \\ \\
&\begin{array}{l l l l}
cpat & ::=     & tag \; \{x\}* & \; \text{constant node pattern} \\
     & \; \mid & tag             & \; \text{single tag pattern} \\
     & \; \mid & lit             & \; \text{literal pattern} \\
\end{array} \\ \\
&\begin{array}{l l}
\{...\}  & \text{means 0 or 1 times}    \\
\{...\}* & \text{means 0 or more times} \\
\end{array} 
\end{empheq}
\caption{GRIN syntax. }
\label{fig:grin-syntax}
\end{figure*}
\endgroup


\subsection{Code generation}
The current implementation of GRIN only compiles a subset of Agda which is lambda lifted, first order, and monomorphic.
%\begin{figure}[hb!]
\begin{code}
downFrom : ℕ → List ℕ
downFrom zero = []
downFrom (suc n) = n ∷ downFrom n 

sum : List ℕ → ℕ
sum [] = 0
sum (x ∷ xs) = x + sum xs

main = sum (downFrom 100) 
\end{code}
%\caption{Agda example program}
%\label{fig:agda-program}
%\end{figure}

Our back-end starts by converting the program into the treeless syntax.
The treeless syntax has explicit case expressions which use A-normal-form, meaning 
that the scrutinee is always a variable, and the alternatives cannot be nested or overlap.
Following is the treeless representation of \AgdaFunction{downFrom}.

\begin{lstlisting}[language=treeless, xleftmargin=24pt]
downFrom x7 = case x7 of
  0 → []
  _ → let x5 = 1
          x4 = _-_ x7 x5
          x3 = downFrom x4 in 
      _$∷$_ x4 x3
\end{lstlisting}
The implementation uses de Bruijn indices to represent variables, but this paper uses variable names to make it more readable. 
During this phase, we also transform the program so applications only take variables as operands.

GRIN is very similar to the treeless syntax, but instead of let-expressions we use the builtin state monad to bind variables and sequence operations.
The monadic operations are \lstinline{unit}, \lstinline{store}, \lstinline{fetch}, and \lstinline{update}. 
The bind operator ";" is infix and right-associative.
We can translate "\lstinline[language=treeless]{let x = $\emph{val}$ in foo x}" lazily
by allocating the value and passing the pointer as an argument to the function: "\lstinline[]{store $\emph{val}$ ; λ x → foo x}".
Here, \emph{val} must be a constant node value. 
A constant node is a tag followed by a sequence of arguments. 
We can pattern match on a tag with the case expression to determine the kind.
Tags are prefixed with either a "C" if it is a constructor value or an "F" for suspended function applications.
The node arguments are usually pointers to other heap-allocated nodes, but they can also be unboxed values.
For example, the boxed integer tag \lstinline{Cnat} accepts one unboxed integer.

\begin{lstlisting}[xleftmargin=24pt]
downFrom x7 =
  eval x7 ; λ Cnat x6 →
  case x6 of
    0 → unit (C[])
    _ →
      store (Cnat 1) ; λ x5 →
      store (F_-_ x7 x5) ; λ x4 →
      store (FdownFrom x4) ; λ x3 →
      unit (C_$∷$_ x4 x3)
\end{lstlisting}

\label{sec:analysis-and-transformations}
\subsection{Analysis and transformations}
The most important GRIN transformation is \emph{eval inlining}. 
\lstinline{eval} is a normal GRIN function which forces suspended computations to its weak head normal form.
There are no suspended computations in GRIN and all values are weak head normal form.
Thus, "suspended computation" and "weak head normal form" should always refer to the corresponding representation in the source program.
In the above function, "\lstinline{eval x7 ; λ Cnat x6 → ...}" evaluates the value at the pointer (\lstinline{x7}) to a boxed integer \lstinline{Cnat x6}.

Eval inlining generates a specialized \lstinline{eval} function for each call site.
To evaluate a suspended computation, we load the node from the heap using \lstinline{fetch}. 
Then, we pattern match on the possible nodes. 
Constructor nodes are already in weak head normal form so they are left unchanged.
Function nodes need to be evaluated by applying the arguments to the corresponding function.
Finally, the heap is updated with the evaluated value.

\begin{lstlisting}[xleftmargin=24pt]
downFrom x7 =
  (fetch x7 ; λ x34 →
   (case x34 of
      Cnat x36 → unit (Cnat x36)
      F_-_ x37 x38 → _-_ x37 x38
   ) ; λ x35 →
   update x7 x34 ; λ () →
   unit x35
  ) ; λ Cnat x6 →
  case x6 of
    0 → unit (C[])
    _ →
      store (Cnat 1) ; λ x5 →
      store (F_-_ x7 x5) ; λ x4 →
      store (FdownFrom x4) ; λ x3 →
      unit (C_$∷$_ x4 x3)
\end{lstlisting}

% TODO fix ugly
Eval inlining require a set of possible nodes for each abstract heap location.
The set needs to be relatively small, or otherwise an excessive amount of code will be generated.
We use the \emph{heap points-to} analysis \citep{johnsson1991}.
The analysis is interprocedural, meaning that multiple functions need to be analyzed together.
We will not go into detail about the algorithm, as it is thoroughly described in \citep{boquist1996}. 
Instead, this paper will only provide a general intuition of the algorithm.
Consider the inlined evaluation in \lstinline{downFrom}.
There are two tags in the case expression: \lstinline{F_-_} and \lstinline{Cnat}. 
\lstinline{F_-_} comes from the suspended recursive call inside \lstinline{downFrom}, and 
\lstinline{Cnat} is from the \lstinline{update} operation and the suspended call to \lstinline{downFrom} in the main function.

\begin{lstlisting}[xleftmargin=24pt]
main =
  store (Cnat 100) ; λ x20 →
  store (FdownFrom x20) ; λ x19 →
  sum x19 ; λ Cnat x18 →
  printf x18
\end{lstlisting}

\citeauthor{boquist1999}'s thesis presents 24 transformations divided into two groups: simplifying transformations and optimizing 
transformations \citep{boquist1999}. 
The simplifying transformations are necessary for the code generator and are all implemented, except \emph{inlining calls to apply}
which is used for partially applied functions. 
The optimizing transformations significantly alter the program and achieve similar effects to deforestation \citep{wadler1988} and listlessness \citep{wadler1984}.
We have only implemented \emph{copy propagation}.
This project aims to combine lazy functional programming with precise reference counting. 
Producing the most optimized code is out of the scope of this project. 
However, this is something we would like to explore in future research.

\section{Precise reference counting}
After the GRIN transformations, we insert reference counting operations to automatically manage memory.
We use an algorithm based on Perceus \citep{reinking2021}. 
Perceus is a deterministic syntax-directed algorithm for the linear resource calculus $λ₁$.
$λ₁$ is an untyped lambda calculus extended with explicit binds and pattern matching.
Our implementation uses GRIN which have explicit memory operations and different calling conventions.
In this section, we give brief a overview of the algorithm and discuss some challenges when adapting Perceus to GRIN. 
We also describe two optimizations: \emph{drop specialization} and \emph{dup/drop fusion}.

The algorithm uses two sets of resource tokens; an owned environment and a borrowed environment. 
Elements in the owned environment must be consumed exactly once. 
We consume a value by calling the function \lstinline{drop}, or by transfer ownership to another consumer.
An example of this is \lstinline{main} which require no reference counting operations because it transfers ownership of both of its allocations.
The allocation "\lstinline{store (Cnat 100) ; λ x20 →}" is consumed by the suspended computation "\lstinline{store (FdownFrom x20) ; λ x19 →}", which in turn is consumed by "\lstinline{sum x19}".
Elements in the borrowed environment can only be applied to non-consuming operations, such as pattern matching. 
We can promote an element from the borrowed environment to the owned environment by calling the function \lstinline{dup}.

\begin{figure*}[hp]
\begin{mdframed}
\centering
\setlength{\fboxsep}{0pt} % padding for border
\begin{subfigure}[t]{0.50\textwidth}
\centering
\begin{lstlisting}
sum x14 =
  fetch x14 [2] ; λ x40 →
  downFrom x40 ; λ x59 x60 x61 →
  case x59 of
    [] →
      update x14 (C[]) ; λ () →
      !\hl{drop x14 ; λ () →}!
      unit (Cnat 0)
    _$∷$_ →
      !\hl{dup x61 ; λ () →}!
      !\hl{dup x60 ; λ () →}!
      update x14 (C_$∷$_ x60 x61) ; λ () →
      !\hl{drop x14 ; λ () →}!
      store (Fsum x61) ; λ x10 →
      _+_ x10 x61
\end{lstlisting}
\caption{dup/drop insertion}
\label{fig:drop-insert}
\end{subfigure}\par\medskip
\begin{subfigure}[b]{0.48\textwidth}
\centering
\begin{lstlisting}
sum x14 =
  fetch x14 [2] ; λ x40 →
  downFrom x40 ; λ x59 x60 x61 →
  case x59 of
    [] →
      update x14 (C[]) ; λ () →
      fetch x14 [0] ; λ x499 →
      (case x499 of
         1 → free x14
         _ →
           PSub x499 1 ; λ x498 →
           update x14 [0] x498
      ) ; λ () →
      unit (Cnat 0)
    _$∷$_ →
      !\hl{dup x61 ; λ () →}!
      !\hl{dup x60 ; λ () →}!
      update x14 (C_$∷$_ x60 x61) ; λ () →
      fetch x14 [0] ; λ x501 →
      (case x501 of
         1 →
           !\hl{drop x61 ; λ () →}!
           !\hl{drop x60 ; λ () →}!
           free x14
         _ →
           PSub x501 1 ; λ x500 →
           update x14 [0] x500
      ) ; λ () →
      store (Fsum x61) ; λ x10 →
      _+_ x10 x61
\end{lstlisting}
\caption{drop specialization}
\label{fig:drop-spec}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
\begin{lstlisting}[showlines=true]
sum x14 =
  fetch x14 [2] ; λ x40 →
  downFrom x40 ; λ x59 x60 x61 →
  case x59 of
    [] →
      update x14 (C[]) ; λ () →
      fetch x14 [0] ; λ x499 →
      (case x499 of
         1 → free x14
         _ →
           PSub x499 1 ; λ x498 →
           update x14 [0] x498
      ) ; λ () →
      unit (Cnat 0)
    _$∷$_ →
      update x14 (C_$∷$_ x60 x61) ; λ () →
      fetch x14 [0] ; λ x501 →
      (case x501 of
         1 →
           free x14
         _ →
           !\hl{dup x61 ; λ () →}!
           !\hl{dup x60 ; λ () →}!
           PSub x501 1 ; λ x500 →
           update x14 [0] x500
      ) ; λ () →
      store (Fsum x61) ; λ x10 →
      _+_ x10 x61


\end{lstlisting}
\caption{dup push-down and dup/drop fusion}
\label{fig:dup/drop-fusion}
\end{subfigure}
\end{mdframed}
\caption{Perceus transformations}
\label{fig:perceus}
\end{figure*}

Figure \ref{fig:drop-insert} presents the function \lstinline{sum} with reference counting operations inserted and highlighted in gray.
Many aspects of adapting Perceus to GRIN are present in \lstinline{sum}. 
For example, we can conclude that the operations \lstinline{fetch} and \lstinline{update} must be borrowing operations. 
This is evident because both \lstinline{fetch} and \lstinline{update} use \lstinline{x14} prior to it being explicitly dropped.
We can also conclude that \lstinline{fetch} bind variables that extend the owned environment.
Meanwhile, the bound variables of function applications extend the borrowed environment.

One of the goals of GRIN is to improve register utilization for lazy functional languages \citep{boquist1999}.
As such, the result of function applications, \lstinline{fetch}, and \lstinline{unit} are regular values stored in registers.
There is no point to reference count values in registers, so we need to treat pointer variables and non-pointer variables differently.
This is in contrast to the calculus which Perceus is defined for, $λ₁$, where all values except variables are heap-allocated \citep{reinking2021}.
Another difference is that functions in GRIN are not allowed to return unboxed pointers. 
Moreover, all function calls return explicit nodes rather than node variables. 
For example: "\lstinline{downFrom x40 ; λ x59 x60 x61 → ...}".
This i problematic because \lstinline{x60} and \lstinline{x61} are undefined when \lstinline{downFrom} returns the empty list.
Therefore, we are only allowed to \lstinline{dup} the variables once the tag is known.

As a result of GRIN's explicit memory operations, we can describe the Perceus primitives \lstinline{dup}, \lstinline{drop}, \lstinline{is-unique}, \lstinline{decref}, and \lstinline{free} with GRIN's existing constructs.
GRIN lacks a primitive for deallocating memory, so \lstinline{free} is just a foreign function call to libc's \lstinline{free}. 
However, our implementation of \lstinline{drop} is unsatisfactory. 
Nodes of different tags vary in arity and the arguments can be either boxed or unboxed.
Therefore, we need to pattern match on all possible tags to drop the child references. 
This is similar to the problem with a general \lstinline{eval} function (Section \ref{sec:analysis-and-transformations}). 
A crucial difference is that \lstinline{drop} is recursive, so we cannot always eliminate the general function by specialization and inlining.
In Figure \ref{fig:drop-spec}, we specialize both calls to \lstinline{drop}.
This eliminates all reference counting operations in the branch for the empty list.
Then, we push down the \lstinline{dup} operations and eliminate \lstinline{dup}/\lstinline{drop} pairs.
This optimization is called \emph{dup/drop fusion} and the result is presented in Figure \ref{fig:dup/drop-fusion}.
We can eliminate the general \lstinline{drop} function completely for our example program, but this is not always the case. 
\citeauthor{reinking2021} presents an additional optimization called \emph{reuse analysis}, which perfoms destructive updates when possible.
This transformation is not yet implemented.

\section{Result}
We have implemented a GRIN interpreter and an LLVM code generator to check that our compiler works and that the programs reclaim all the allocated memory. 
Our implementation of the code generator is simple. 
GRIN does not demand a specific memory layout for the node values.
The only requirements are that tags should be unique and easy to extract \citep{boquist1999}.
We use an array of four 64-bit integer values for all heap-allocated nodes. 
The first two address spaces contain the reference count and the tag, respectively.
The node arguments occupy the rest of the array.
LLVM IR is a statically typed language, while GRIN is untyped.
This discrepancy is not an issue because all functions return nodes, and all variables are pointers or integers.
Hence, we store the pointers as integer values and convert them to the pointer type (\lstinline{ptr}) as required.
However, we will probably develop a type system for GRIN once we switch to a more sophisticated memory layout and implement the \emph{general unboxing} optimization \citep{boquist1999}.

The GRIN interpreter is convenient because it can evaluate all programs after the eval inlining transformation. 
Meanwhile, the code generator only works for programs after the simplifying transformations (see Section \ref{sec:analysis-and-transformations}).
It is also easier to collect information on the program evaluation.
For instance, the final version of our example program allocates the following nodes: 101 \lstinline{Cnat}, 101 \lstinline{FdownFrom}, 100 \lstinline{F_-_},  and 100 \lstinline{Fsum}.
A total of 402 allocations for our tiny example program is excessive. 
The main culprit is too much laziness. 
Another contributing factor is that we always allocate new memory instead of reusing previous allocations

% \begin{itemize}
% \item Short text about tailcalls
% \item Currenlty we use libc's \texttt{malloc} and \texttt{free}, however, \citeauthor{pinto2023} suggest that these should be implemented in assembly.
% \end{itemize}

% There are 402 allocations in our example program (page 2): 

% \begin{itemize}
% \item Stack overflows (tail calls partly remedy this)
% \item Integer overflow
% \item The necessary parts of GRIN and Perceus is implemented but a lot of optimizations are 
      % left on the table. In GRIN we have mostly implemented the necessary simplifying transformations,
      % which turns GRIN into a state which is suitable for the code generator.
      % We haven't implemented drop specialization or heap reuse analysis.
% \end{itemize}

% \section{Relevant Work}
% Lean and Koka: reference counting and reuse
% Swift: automatic reference counting (ARC), and plans of borrowing
% AST \& Rust: safe manual memory management through proofs and the borrow checker, respectively
\section{Conclusion and Future Work}
In this paper, we combine lazy functional programming with precise reference counting.
Our implementation compiles Agda to GRIN and extends GRIN with precise reference counting instructions. 
Then, we compile GRIN to LLVM and show that the program reclaims all the memory.
Currently, our implementation allocates a lot of nodes. 
In future research, we would like to minimize allocations by implementing the rest of the GRIN optimizing transformations and the Perceus reuse analysis.
We are also interested in developing a type system for GRIN and compiling a larger set of Agda programs.

% \begin{itemize} 
% \item implement reuse analysis and the rest of transformation to avoid uneccessary allocations and laziness.
%\item It would cool to benchmark our work but we lack many optimization.
%\item The current implementation of GRIN and Perceus have not yet implementation many optimization transformations. For example, GRIN lacks function inlining, generalized unboxing, and arity raising. Perceus lacks it two most import transformations; drop specialization and reuse analysis.
%\item Another huge optimization on is a strictness analysis. 
%\item Add reuse and borrowing
%\item Utilse GRIN's whole program compilation strategy and the heap points-to analysis to statically determine unshared values during compile time, and thus minimizing the number of reference countinging operations.
%\item It would also be intresting to utilse 0-modality (erasure) in Agda's type system, and later also 1-modality when Agda gets it.
%\item In the current naive implementation drop enumerates all the possible tags 
%\end{itemize}

% Lambda lifting
% The rest of the GRIN transformations and optimizations
% Partial applications (P-tags and the apply operation)
% Different allocator? mimalloc?
% Using type information (multiplicites: 0, (1), ω)


\printbibliography

\end{document}


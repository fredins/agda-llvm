% !TEX program = lualatex
\documentclass[10pt, twocolumn]{article}
% \usepackage{a4wide}

%\usepackage[a4paper, total={8.5in, 11in}]{geometry}
% \usepackage[a4paper]{geometry}
\usepackage[a4paper, margin=2.5cm]{geometry}
%\setlength{\textheight}{1.1\textheight}

% Support for Agda code.
\usepackage{agda}

\usepackage{fontspec}
\newfontfamily{\AgdaSerifFont}{Latin Modern Roman}
\newfontfamily{\AgdaSansSerifFont}{Latin Modern Sans}
\newfontfamily{\AgdaTypewriterFont}{Latin Modern Mono}
\renewcommand{\AgdaFontStyle}[1]{{\AgdaSansSerifFont{}#1}}
\renewcommand{\AgdaKeywordFontStyle}[1]{{\AgdaSansSerifFont{}#1}}
\renewcommand{\AgdaStringFontStyle}[1]{{\AgdaTypewriterFont{}#1}}
\renewcommand{\AgdaCommentFontStyle}[1]{{\AgdaTypewriterFont{}#1}}
\renewcommand{\AgdaBoundFontStyle}[1]{\textit{\AgdaSerifFont{}#1}}

% Bibliography
\usepackage[backend=biber, style=apa, natbib=true]{biblatex}
\addbibresource{../bibliography.bib}

% Packages
\usepackage{empheq} % for border around math
\usepackage{listings} % non-agda code blocks
\usepackage{amssymb} % math symbols
\usepackage[]{lmodern} % Latin modern font
\usepackage[labelfont=bf, textfont=it, justification=centering, singlelinecheck=false]{caption} 

% Cosmetics
\linespread{1.25}
\setlength{\fboxsep}{1em} % padding for border

\usepackage{newunicodechar}
\usepackage{colonequals}
\newunicodechar{λ}{\ensuremath{\mathnormal{\lambda}}}
\newunicodechar{∀}{\ensuremath{\mathnormal{\forall}}}
\newunicodechar{∷}{\ensuremath{\mathnormal{\coloncolon}}}
\newunicodechar{ω}{\ensuremath{\mathnormal{\omega}}}
\newunicodechar{ℕ}{\ensuremath{\mathbb{N}}}

\newunicodechar{₁}{\ensuremath{{}_1}}
\newunicodechar{₂}{\ensuremath{{}_2}}
\newunicodechar{₃}{\ensuremath{{}_3}}
\newunicodechar{₄}{\ensuremath{{}_4}}
\newunicodechar{₅}{\ensuremath{{}_5}}
\newunicodechar{₆}{\ensuremath{{}_6}}
\newunicodechar{₇}{\ensuremath{{}_7}}
\newunicodechar{₈}{\ensuremath{{}_8}}
\newunicodechar{₉}{\ensuremath{{}_9}}


\usepackage{listings}
\lstdefinelanguage{treeless}{
keywords={case, of, let, in}
}
\lstdefinelanguage{grin}{
keywords={case, of, store, update, unit, fetch}
}

\lstset{
frame=none,
xleftmargin=24pt,
% xrightmargin=10pt,
% xleftmargin=.2\textwidth, 
% xrightmargin=.2\textwidth,
aboveskip=8pt,
belowskip=8pt,
framexleftmargin=4pt,
framesep=10pt,
stepnumber=1,
numbers=none,
numbersep=5pt,
numberstyle=\ttfamily\tiny\color[gray]{0.3},
%basicstyle=\ttfamily\small,
%keywordstyle=\bfseries,
basicstyle=\ttfamily\fontseries{l}\selectfont,
keywordstyle=\ttfamily\fontseries{b}\selectfont,
captionpos=b,
language=grin,
commentstyle=\it,
columns=flexible,
keepspaces=true,
mathescape=true,
}

\title{ Precise reference counting for lazy functional languages with interprocedural analysis}
\author{Martin Fredin}
\date{June 2023}

\begin{document}

\maketitle


\begin{code}[hide]
open import Agda.Builtin.Nat using (suc; zero; _+_) renaming (Nat to ℕ) 

infixr 5 _∷_
data List A : Set where
  []  : List A
  _∷_ : (x : A) (xs : List A) → List A
\end{code}

\begin{abstract}
Precise reference counting is a technique by \citeauthor{reinking2021} that uses ownership to deallocate objects as soon as possible. 
The algorithm is called Perceus, and as of this writing, it has only been implemented for eager functional languages.
This paper describes the implementation of a new lazy compiler back-end for the Agda programming language with 
precise reference counting. 
The compiler uses \citeauthor{boquist1999} and \citeauthor{johnsson1991}'s intermediate language GRIN to compile lazy programs. 
GRIN uses interprocedural analysis to inline evaluation of suspended computations.
We extend GRIN with a variant of Perceus, and demonstrate the applicability of combining lazy functional programming with precise reference counting by developing a GRIN interpreter and a LLVM code generator. 
\end{abstract}

\section{Introduction}

Reference counting \citep{collins1960} is a memory management technique which can detect and free resources as soon as they are no longer needed, allowing memory reuse and destructive updates. 
Common reference counting algorithms are easy to implement; each allocation contains an extra field which tracks the number of references to a object, and reclaims the heap space once the reference count drops to zero.
The number of references to a object is updated by interleaved reference counting operations (\texttt{dup} and \texttt{drop}), which increments and decrements the reference count at runtime. 
As a result of the interleaved collection strategy, memory usage remain low and the throughput is continuous throughout the computation\footnote{Reference counted programs may introduce pauses similar to tracing garbage collectors. For example, when decrementing a long linked list all at once.} \citep{jones1996}.
Still, tracing garbage collectors are usually favored over reference counting implementations due to cheaper allocations, higher throughput, and the ability to collect cyclic data structures.

\citet{reinking2021} reexamine reference counting with a new approach; utilizing static guarantees to make the algorithm precise, so objects can be deallocated as soon as possible.
They present a formalized algorithm called Perceus which ensure preciseness. 
Perceus is implemented in the functional language Koka, along with two optimizations for reducing reference counting operations and reusing memory.
This builds upon previous work by \citet{ullrich2021} in the Lean programming language and theorem prover. 

Both Koka and Lean are, however, eagerly evaluated. 
Lazy languages pose an extra challenge for compiler writers because of their unintuitive control flow. 
In this paper, we adapt the Perceus algorithm to a new lazy compiler back-end for the Agda programming language and proof assistant.
To do this, we first transform Agda into an intermediate language called GRIN \citep{johnsson1991}.

\section{Graph Reduction Intermediate Notation}
In \citeyear{johnsson1991}, \citeauthor{johnsson1991} presented the Graph Reduction Intermediate Notation (GRIN) as an imperative version of the G-machine \citep{johnsson1984}, where lexically scoped variables are stored in registers instead of the stack. 
Later, GRIN was reformulated with a more "functional flavor" \citep{boquist1995}.
In this project, we introduce an additional variant of GRIN adapted for the internal representation of Agda and precise reference counting. 

The syntax of our variant are shown in Figure \ref{fig:grin-syntax}.
There are 4 kinds of constructs; terms, values, lambda patterns, and case patterns.
All syntactically correct expressions are not valid. For example, the value at the function position of an application must be either a top-level function (\emph{def}) or a primitive (\emph{prim}). It cannot be a variable because
there are no indirect function calls in GRIN. Likewise, top-level functions cannot be passed 
as arguments because GRIN is a first-order language.

\begin{figure*}[htbp]
\centering
\begin{empheq}[box=\fbox]{align*}
&\begin{array}{l l l l}
term & ::=      & term \; ; \; \lambda lpat \rightarrow term                & \; \text{binding} \\
     & \; \mid  & \texttt{case} \; val \; \texttt{of} \; term \; \{calt\}*  & \; \text{case} \\
     & \; \mid  & val \; \{val\}*                                           & \; \text{application} \\
     & \; \mid  & \texttt{unit} \; val                                      & \; \text{return value} \\
     & \; \mid  & \texttt{store} \; val                                     & \; \text{allocate new heap node} \\
        & \; \mid  & \texttt{fetch} \; \{tag\} \; n \;  \{i\}                  & \; \text{load heap node} \\
        & \; \mid  & \texttt{update} \; \{tag\} \; n \; \{i\} \; val           & \; \text{overwrite heap node} \\
        & \; \mid  & \texttt{unreachable}                                      & \; \text{unreachable} \\
\end{array} \\ \\
&\begin{array}{l l l l}
val & ::=     & tag \; \{val\}* & \; \text{constant node} \\
    & \; \mid & n \; \{val\}*   & \; \text{variable node} \\
    & \; \mid & tag             & \; \text{single tag} \\
    & \; \mid & ()              & \; \text{empty} \\
    & \; \mid & lit             & \; \text{literal} \\
    & \; \mid & n               & \; \text{variable (de Bruijn index)} \\
    & \; \mid & def             & \; \text{function definition} \\
    & \; \mid & prim            & \; \text{primitive definition} \\
\end{array} \\ \\
&\begin{array}{l l l l}
lpat & ::=     & tag \; \{x\}* & \; \text{constant node pattern} \\
     & \; \mid & x \; \{x\}*   & \; \text{variable node pattern} \\
     & \; \mid & ()            & \; \text{empty pattern} \\
     & \; \mid & x             & \; \text{variable pattern} \\
\end{array} \\ \\
&\begin{array}{l l l l}
cpat & ::=     & tag \; \{x\}* & \; \text{constant node pattern} \\
     & \; \mid & tag             & \; \text{single tag pattern} \\
     & \; \mid & lit             & \; \text{literal pattern} \\
\end{array} \\ \\
&\begin{array}{l l}
\{...\}  & \text{means 0 or 1 times}    \\
\{...\}* & \text{means 0 or more times} \\
\end{array} 
\end{empheq}
\caption{GRIN syntax. }
\label{fig:grin-syntax}
\end{figure*}


\subsection{Code generation}
The current implementation of GRIN only compiles a subset of Agda which is lambda lifted, first order, and monomorphic.
%\begin{figure}[hb!]
\begin{code}
downFrom : ℕ → List ℕ
downFrom zero = []
downFrom (suc n) = n ∷ downFrom n 

sum : List ℕ → ℕ
sum [] = 0
sum (x ∷ xs) = x + sum xs

main = sum (downFrom 100) 
\end{code}
%\caption{Agda example program}
%\label{fig:agda-program}
%\end{figure}

Our back-end starts by converting the program into the treeless syntax.
The treeless syntax has explicit case expressions which uses A-normal-form, meaning 
that the scrutinee is always a variable and the alternatives cannot be nested or overlap.
Following is the treeless representation of \AgdaFunction{downFrom}.

\begin{lstlisting}[language=treeless]
downFrom x$₁$ = case x$₁$ of
  0 → []
  _ → let x$₂$ = 1
          x$₃$ = _-_ x$₁$ x$₂$
          x$₄$ = downFrom x$₃$ in 
      _$∷$_ x$₃$ x$₄$
          
\end{lstlisting}
The implementation uses de Bruijn indices to represent variables, but this paper uses variable names to make it more readable. 
During this phase, we also transform the program so applications only take variables as operands.

GRIN is very similar to the treelss syntax, but instead of the let-expressions we use the builtin state monad to bind variables and sequence operations.
The monadic operations are \lstinline{unit}, \lstinline{store}, \lstinline{fetch}, and \lstinline{update}. 
The bind operator ";" is infix and right-associative.

We can translate "\lstinline[language=treeless]{let x = $\emph{val}$ in foo x}" lazily
by allocating the value and passing the pointer as an argument to the function "\lstinline[]{store $\emph{val}$ ; λ x → foo x}".
Here, \emph{val} must be a constant node value. 
A constant node is a tag followed by a sequence of arguments. 
We can pattern match on a tag with the case expression to determine the kind.
Tags are prefixed with either a "C" if it is a constructor value, or an "F" for suspended function applications.
The node arguments are usually pointers to other heap allocated nodes, but they can also be unboxed values.
For example, the boxed integer tag "\lstinline{Cnat}" accepts one unboxed integer.

\begin{lstlisting}
downFrom x$₁$ =
  eval x$₁$ ; λ Cnat x$₂$ →
  case x$₂$ of
    0 → unit ([])
    _ →
      store (Cnat 1) ; λ x$₃$ →
      store (F_-_ x$₁$ x$₃$) ; λ x$₄$ →
      store (FdownFrom x$₄$) ; λ x$₅$ →
      unit (C_$∷$_ x$₄$ x$₅$)
\end{lstlisting}

\subsection{Analysis and transformations}
The most important GRIN transformation is \emph{eval inlining}. 
\lstinline{eval} is a normal GRIN function which forces suspended computations to it's weak head normal form.
An example of this is "\lstinline{eval x$₁$ ; λ Cnat x$₂$ → ...}" in the function above.
In this example, the value at the pointer (\lstinline{x$₁$}) is evaluated to a boxed integer \lstinline{Cnat x$₂$}.
Eval inlining generates a specialized \lstinline{eval} function for each call site.
To evaluate a suspended computation, we load the node from the heap using \lstinline{fetch}. 
Then, we pattern match over the possible nodes. 
Constructor nodes are already in weak head normal form so they are left unchanged.
Function nodes need to be evaluated by applying the arguments to the corresponding function.
Finally, the heap is updated with the evaluated value.

\begin{lstlisting}
downFrom x$₁$ =
  (fetch x$₁$ ; λ x$₆$ →
   (case x$₆$ of
      Cnat x$₇$ → unit (Cnat x$₇$)
      F_-_ x$₈$ x$₉$ → _-_ x$₈$ x$₉$
   ) ; λ x$_{10}$ →
   update x$₁$ x$_{10}$ ; λ () →
   unit 0
  ) ; λ Cnat x$₂$ →
  case x$₂$ of
    0 → unit ([])
    _ →
      store (Cnat 1) ; λ x$₃$ →
      store (F_-_ x$₁$ x$₃$) ; λ x$₄$ →
      store (FdownFrom x$₄$) ; λ x$₅$ →
      unit (C_$∷$_ x$₄$ x$₅$)
\end{lstlisting}

Eval inlining require a set of possible nodes for each abstract heap location.
The set needs to be relatively small, or otherwise an excessive amount of code will be generated.
We will use the \emph{heap points-to} analysis \citep{johnsson1991}.
The analysis is interprocedural, meaning that multiple functions need to be analyzed together.
We will not go into detail about the algorithm, as it is thoroughly described in \citep{boquist1996}. 
Instead, this paper will only provide a general intuition of the algorithm.
Consider the inlined evaluation in \lstinline{downFrom}.
There are two tags in the case expression. 
\lstinline{F_-_} comes from the (lazy) recursive call inside \lstinline{downFrom}, and 
\lstinline{Cnat} is from the \lstinline{update} operation and the call to \lstinline{downFrom} in the main function.


\begin{lstlisting}
main =
  store (Cnat 100) ; λ x$_{11}$ →
  store (downFrom x$_{11}$) ; λ x$_{12}$ →
  sum x$_{12}$ ; λ Cnat x$_{13}$ →
  printf x$_{13}$
\end{lstlisting}

\citeauthor{boquist1999}'s thesis contains 24 transformations divided into two groups: simplifying transformations and optimizing 
transformations. 
The simplifying transformations are necessary for the code generator and are all implemented, except \emph{inlining calls to apply}
which is used for partially applied functions. 
For the optimizing transformations, only \emph{copy propagation} is implemented.
The reason for this is...

% TODO describe many powerful optimization like inlining, arity raising, and general unboxing.

\section{Precise reference counting}
% TODO explain the Perceus algorithm

In GRIN, we have to be explicit about allocations, retrieving nodes from the heap, and overwriting heap nodes.
As a result, the Perceus primitives \texttt{dup}, \texttt{drop}, \texttt{is-unique}, \texttt{decref}, and \texttt{free} 
can be described with GRIN's exisiting constructs.\footnote{This only possible in our slightly modified version of 
GRIN. \citeauthor{boquist1999}'s specification of GRIN could not overwrite individual fields of a heap node 
using \texttt{update}.}
Although, GRIN does not have a primitive for freeing memory, this can be simulated by a function call 
to libc's \texttt{free}.
 

\section{LLVM code generator}
\begin{itemize}
\item GRIN in unopinonated about the node representation. There only on reguiremnt: there should be 
      an easy way to extract the tag.
\item Explain node structure \texttt{[4 x i64]}
\item Short text about tailcalls
\item Currenlty we do not need a type system because all functions 
      return full nodes but after the general unboxing transformation 
      this will change. \citet{podlovics2021} have also developed a 
      LLVM back-end for GRIN and they needed a type system for the mentioned 
      reason.
\item Currenlty we use libc's \texttt{malloc} and \texttt{free}, however, \citeauthor{pinto2023} suggest that these should be implemented in assembly.
\item Non-atomic reference count operations.
\end{itemize}

\section{Result}

To test that our compiler back-end actually works and that all memory is reclaimed, we implemented a GRIN interpreter and a LLVM code generator.
We discovered that our back-end allocate many objects. 

There are 402 allocations in our example program (page 2): 
101 \texttt{Cnat} nodes, 101 \texttt{FdownFrom} nodes, 100 \texttt{F\_-\_} nodes, 100 \texttt{Fsum} nodes.

\begin{itemize}
\item Stack overflows (tail calls partly remedy this)
\item Integer overflow
\item The necessary parts of GRIN and Perceus is implemented but a lot of optimizations are 
      left on the table. In GRIN we have mostly implemented the necessary simplifying transformations,
      which turns GRIN into a state which is suitable for the code generator.
      We haven't implemented drop specialization or heap reuse analysis.
\end{itemize}

\section{Relevant Work}
% Lean and Koka: reference counting and reuse
% Swift: automatic reference counting (ARC), and plans of borrowing
% AST \& Rust: safe manual memory management through proofs and the borrow checker, respectively

\section{Conclusion and Future Work}
\begin{itemize}
\item It would cool to benchmark our work but we lack many optimization.
\item The current implementation of GRIN and Perceus have not yet implementation many optimization transformations. For example, GRIN lacks function inlining, generalized unboxing, and arity raising. Perceus lacks it two most import transformations; drop specialization and reuse analysis.
\item Another huge optimization on is a strictness analysis. 
\item Add reuse and borrowing
\item Utilse GRIN's whole program compilation strategy and the heap points-to analysis to statically determine unshared values during compile time, and thus minimizing the number of reference countinging operations.
\item It would also be intresting to utilse 0-modality (erasure) in Agda's type system, and later also 1-modality when Agda gets it.
\item In the current naive implementation drop enumerates all the possible tags 
\end{itemize}

% Lambda lifting
% The rest of the GRIN transformations and optimizations
% Partial applications (P-tags and the apply operation)
% Different allocator? mimalloc?
% Using type information (multiplicites: 0, (1), ω)


\printbibliography

\end{document}

